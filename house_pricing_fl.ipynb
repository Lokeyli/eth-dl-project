{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Dict, Optional, Union\n",
    "\n",
    "import os,os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents, ClientManager\n",
    "from flwr.server.strategy import Strategy, FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
    "from flwr.common import FitRes, Parameters, parameters_to_ndarrays\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common.logger import set_logger_propagation\n",
    "\n",
    "from enum import Enum\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configurable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(device)\n",
    "\n",
    "# Number of clients and features\n",
    "NUM_CLIENTS = 5\n",
    "NUM_FEATURES = 7\n",
    "\n",
    "# Sample size range\n",
    "MIN_SAMPLES = 1000\n",
    "MAX_SAMPLES = 2000\n",
    "\n",
    "# Number of rouge clients\n",
    "NUM_ROUGE_CLIENTS = 0\n",
    "\n",
    "# Distribution configuration\n",
    "DISTRIBUTIONS = {\n",
    "    'Square Meters': {'type': 'normal', 'mu_range': (100, 300), 'sigma_range': (10, 30)},\n",
    "    'Year Built': {'type': 'normal', 'mu_range': (1950, 2020), 'sigma_range': (1, 5)},\n",
    "    'Neighborhood Quality': {'type': 'categorical', 'categories': ['Low', 'Medium', 'High'], 'prob_range': [(0.5, 0.3, 0.2), (0.3, 0.4, 0.3)]},\n",
    "    'Distance to Amenities': {'type': 'uniform', 'low_range': (100, 500), 'high_range': (500, 1000)},\n",
    "    'Number of Rooms': {'type': 'poisson', 'lambda_range': (2, 5)},\n",
    "    #'Lot Size': {'type': 'normal', 'mu_range': (500, 2000), 'sigma_range': (100, 300)},\n",
    "    'House Style': {'type': 'categorical', 'categories': ['Single Family', 'Condo', 'Townhouse'], 'prob_range': [(0.6, 0.3, 0.1), (0.4, 0.4, 0.2)]},\n",
    "    'Local Economic Index': {'type': 'normal', 'mu_range': (50, 150), 'sigma_range': (10, 30)}\n",
    "}\n",
    "\n",
    "DISTRIBUTIONS2 = {\n",
    "    'Square Meters': {'type': 'normal', 'mu_range': (0, 0), 'sigma_range': (1, 1)},\n",
    "    'Year Built': {'type': 'normal', 'mu_range': (0, 0), 'sigma_range': (1, 1)},\n",
    "    'Neighborhood Quality': {'type': 'normal', 'mu_range': (0, 0), 'sigma_range': (1, 1)},\n",
    "    'Distance to Amenities': {'type': 'normal', 'mu_range': (0, 0), 'sigma_range': (1, 1)},\n",
    "    'Number of Rooms': {'type': 'normal', 'mu_range': (0, 0), 'sigma_range': (1, 1)},\n",
    "    'House Style': {'type': 'normal', 'mu_range': (0, 0), 'sigma_range': (1, 1)},\n",
    "    'Local Economic Index': {'type': 'normal', 'mu_range': (0, 0), 'sigma_range': (1, 1)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Utility / Helper Functions & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature(feature_name, dist_params, num_samples):\n",
    "    \"\"\"Generates data for a specific feature based on its distribution.\"\"\"\n",
    "    dist_type = dist_params['type']\n",
    "    if dist_type == 'normal':\n",
    "        mu = np.random.uniform(*dist_params['mu_range'])\n",
    "        sigma = np.random.uniform(*dist_params['sigma_range'])\n",
    "        if feature_name == \"Year Built\":\n",
    "            return np.round(np.random.normal(mu, sigma, num_samples)).astype(int), {'mu': mu, 'sigma': sigma}\n",
    "        return np.random.normal(mu, sigma, num_samples), {'mu': mu, 'sigma': sigma}\n",
    "    elif dist_type == 'uniform':\n",
    "        low = np.random.uniform(*dist_params['low_range'])\n",
    "        high = np.random.uniform(*dist_params['high_range'])\n",
    "        return np.random.uniform(low, high, num_samples), {'low': low, 'high': high}\n",
    "    elif dist_type == 'categorical':\n",
    "        prob = dist_params['prob_range'][np.random.randint(0, len(dist_params['prob_range']))]\n",
    "        return np.random.choice(dist_params['categories'], num_samples, p=prob), {'probabilities': prob}\n",
    "    elif dist_type == 'poisson':\n",
    "        lam = np.random.uniform(*dist_params['lambda_range'])\n",
    "        return np.random.poisson(lam, num_samples), {'lambda': lam}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distribution type: {dist_type}\")\n",
    "    \n",
    "def encode_categorical_features(client_data):\n",
    "    \"\"\"Encodes categorical features as numerical values.\"\"\"\n",
    "    encoded_data = {}\n",
    "    encoding_maps = {}\n",
    "    for feature_name, values in client_data.items():\n",
    "        if isinstance(values[0], str):  # Check if the feature is categorical\n",
    "            unique_values = list(set(values))\n",
    "            encoding_map = {val: idx for idx, val in enumerate(unique_values)}\n",
    "            encoded_data[feature_name] = np.array([encoding_map[val] for val in values])\n",
    "            encoding_maps[feature_name] = encoding_map\n",
    "        else:\n",
    "            encoded_data[feature_name] = values\n",
    "    return encoded_data, encoding_maps\n",
    "\n",
    "def decode_categorical_features(client_data, encoding_maps):\n",
    "    \"\"\"Decodes numerical categorical features back to their string values.\"\"\"\n",
    "    decoded_data = {}\n",
    "    for feature_name, values in client_data.items():\n",
    "        if feature_name in encoding_maps:\n",
    "            decoding_map = {v: k for k, v in encoding_maps[feature_name].items()}\n",
    "            decoded_data[feature_name] = [decoding_map[val] for val in values]\n",
    "        else:\n",
    "            decoded_data[feature_name] = values\n",
    "    return decoded_data\n",
    "\n",
    "def generate_target_variable(features, weights, noise_std=0):\n",
    "    \"\"\"Generates the target variable (house price) as a weighted sum of features with noise.\"\"\"\n",
    "    linear_combination = sum(w * features[i] for i, w in enumerate(weights))\n",
    "    noise = np.random.normal(0, noise_std, len(features[0]))\n",
    "    return linear_combination + noise\n",
    "\n",
    "def add_noise_to_features(client_data, noise_level=0.5):\n",
    "    \"\"\"Adds noise to numerical features in the client data.\"\"\"\n",
    "    noisy_data = {}\n",
    "    for feature_name, feature_values in client_data.items():\n",
    "        if feature_name != 'House Price' and np.issubdtype(type(feature_values[0]), np.number):  # Only numerical features\n",
    "            noise = np.random.normal(0, noise_level * np.std(feature_values), len(feature_values))\n",
    "            noisy_data[feature_name] = feature_values + noise\n",
    "        else:\n",
    "            noisy_data[feature_name] = feature_values\n",
    "    return noisy_data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"Saves a DataFrame to a CSV file.\"\"\"\n",
    "    data.to_csv(filename, index=False)\n",
    "\n",
    "def generate_house_pricing_dataset(\n",
    "    num_clients=5,\n",
    "    num_features=7,\n",
    "    min_samples=1000,\n",
    "    max_samples=10000,\n",
    "    num_rouge_clients=0,\n",
    "    distributions={},\n",
    "    is_sum=False,\n",
    "    path=\"./\",\n",
    "    seed=42):\n",
    "    \"\"\"\n",
    "    Generates house pricing datasets for multiple clients, of which some are rouge (delivering noisy/faulty data).\n",
    "    Returns a list of TensorDatasets, one for each client, where each dataset contains features and targets.\n",
    "\n",
    "    Args:\n",
    "        num_clients (int): Number of clients.\n",
    "        num_features (int): Number of features.\n",
    "        min_samples (int): Minimum samples per client dataset.\n",
    "        max_samples (int): Maximum samples per client dataset.\n",
    "        num_rouge_clients (int): Number of rouge clients delivering noisy data.\n",
    "        distributions (dict): Distributions for feature generation.\n",
    "        is_sum (bool): Wheter the target variable is a linear combination of the features with all weights = 1\n",
    "        path (str): Path to save datasets and metadata.\n",
    "        seed (int): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        List[TensorDataset]: A list where each element is a TensorDataset corresponding to one client's data.\n",
    "    \"\"\"\n",
    "    # Output directory\n",
    "    output_dir = Path(path)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Store TensorDatasets for all clients\n",
    "    client_datasets = []\n",
    "\n",
    "    # Metadata of one dataset creation instance, for trackability\n",
    "    metadata = []\n",
    "\n",
    "    # Select NUM_ROUGLE_CLIENTS many clients to act rouge\n",
    "    np.random.seed(seed)\n",
    "    rouge_clients = set(np.random.choice(range(1, num_clients + 1), num_rouge_clients, replace=False))\n",
    "\n",
    "    # Generate weights for linear combination of the target variable, seed for reproducibility\n",
    "    if is_sum:\n",
    "        weights = np.ones(num_features)\n",
    "    else:\n",
    "        np.random.seed(seed)\n",
    "        weights = np.random.uniform(0.1, 1, num_features)\n",
    "    np.random.seed(None)\n",
    "\n",
    "    #Generate features for each client\n",
    "    for client_id in range(1, num_clients + 1):\n",
    "        # Random number of samples in range [min_samples, max_samples]\n",
    "        num_samples = np.random.randint(min_samples, max_samples + 1)\n",
    "\n",
    "        # Keep track of the data and metadata\n",
    "        client_data = {}\n",
    "        client_metadata = {'Client_ID': client_id, 'Is_Rouge': client_id in rouge_clients}\n",
    "        \n",
    "        # Generate features\n",
    "        for feature_name, dist_params in distributions.items():\n",
    "            feature_data, params = generate_feature(feature_name, dist_params, num_samples)\n",
    "            client_data[feature_name] = feature_data\n",
    "            client_metadata[feature_name] = params\n",
    "\n",
    "        # Add noise for rouge clients\n",
    "        if client_id in rouge_clients:\n",
    "            client_data = add_noise_to_features(client_data)\n",
    "\n",
    "        # Encode categorical features\n",
    "        encoded_client_data, encoding_maps = encode_categorical_features(client_data)\n",
    "\n",
    "        # Generate target variable (house price) as a weighted linear combination\n",
    "        features = [encoded_client_data[feature_name] for feature_name in distributions.keys()]\n",
    "        encoded_client_data['House Price'] = generate_target_variable(features, weights, noise_std=0)\n",
    "\n",
    "        # Convert encoded data to PyTorch tensors\n",
    "        encoded_data = pd.DataFrame(encoded_client_data)\n",
    "        feature_tensor = torch.tensor(encoded_data.drop(columns=[\"House Price\"]).values, dtype=torch.float32)  # All but last column\n",
    "        target_tensor = torch.tensor(encoded_data['House Price'].values.reshape(-1, 1), dtype=torch.float32)  # Last column\n",
    "\n",
    "        # Create TensorDataset for the client\n",
    "        client_dataset = TensorDataset(feature_tensor, target_tensor)\n",
    "        client_datasets.append(client_dataset)\n",
    "    \n",
    "\n",
    "        # Decode categorical features before saving\n",
    "        decoded_client_data = decode_categorical_features(encoded_client_data, encoding_maps)\n",
    "\n",
    "        # Save client dataset to CSV\n",
    "        client_df = pd.DataFrame(decoded_client_data)\n",
    "        save_to_csv(client_df, output_dir / f\"client_{client_id}.csv\")\n",
    "\n",
    "        # Save metadata\n",
    "        client_metadata['Encoding Maps'] = encoding_maps\n",
    "        client_metadata['weights'] = weights\n",
    "        metadata.append(client_metadata)\n",
    "\n",
    "        # Save metadata to a CSV file\n",
    "        metadata_df = pd.DataFrame(metadata)\n",
    "        save_to_csv(metadata_df, output_dir / \"metadata.csv\")\n",
    "\n",
    "    return client_datasets\n",
    "\n",
    "def create_client_loaders(\n",
    "    client_datasets,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    batch_size=16,\n",
    "    seed=42\n",
    "):\n",
    "     \"\"\"\n",
    "    Creates train, validation, and test DataLoaders for each client's TensorDataset.\n",
    "\n",
    "    Args:\n",
    "        client_datasets (list): A list of TensorDatasets, one for each client.\n",
    "        train_ratio (float): Proportion of samples used for training.\n",
    "        val_ratio (float): Proportion of samples used for validation.\n",
    "        batch_size (int): Batch size for the DataLoaders.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains (train_loader, val_loader, test_loader) for a client.\n",
    "    \"\"\"\n",
    "     \n",
    "     torch.manual_seed(seed)\n",
    "\n",
    "     loaders = []\n",
    "\n",
    "     for dataset in client_datasets:\n",
    "         total_samples = len(dataset)\n",
    "         train_len = int(total_samples * train_ratio)\n",
    "         val_len = int(total_samples * val_ratio)\n",
    "         test_len = total_samples - train_len - val_len\n",
    "\n",
    "         # Ensure reproducible splits\n",
    "         generator = torch.Generator().manual_seed(seed)\n",
    "         train_ds, val_ds, test_ds = random_split(\n",
    "             dataset,\n",
    "             lengths=[train_len, val_len, test_len],\n",
    "             generator=generator\n",
    "         )\n",
    "\n",
    "         # Create DataLoaders\n",
    "         train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "         val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "         test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "         loaders.append((train_loader, val_loader, test_loader))\n",
    "\n",
    "     return loaders\n",
    "\n",
    "def load_data(client_id, data_path, seed=42, batch_size=16):\n",
    "    df = pd.read_csv(data_path + f'/client_{client_id}.csv')\n",
    "\n",
    "    # Encode categorical features\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = pd.Categorical(df[col]).codes\n",
    "\n",
    "    # Separate features and target\n",
    "    features = df.drop(columns=[\"House Price\"]).values\n",
    "    target = df[\"House Price\"].values.reshape(-1, 1)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "    # Create a full dataset\n",
    "    full_dataset = TensorDataset(features_tensor, target_tensor)\n",
    "\n",
    "    # Determine lengths for splits\n",
    "    total_len = len(full_dataset)\n",
    "    train_len = int(0.7 * total_len)\n",
    "    val_len = int(0.2 * total_len)\n",
    "    test_len = total_len - train_len - val_len\n",
    "\n",
    "    # Use random_split for reproducible splits\n",
    "    generator = torch.Generator().manual_seed(seed + client_id)  # Client-specific seed\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        full_dataset,\n",
    "        lengths=[train_len, val_len, test_len],\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # print(f\"Client {client_id} stats: mean={df['House Price'].mean()}, std={df['House Price'].std()}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "class TaskType(Enum):\n",
    "\n",
    "    CLASSFICATION = 0\n",
    "    REGRESSION = 1\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def train(net, trainloader, epochs: int, verbose=False, device = \"cpu\", task_type = TaskType.CLASSFICATION):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    if task_type == TaskType.CLASSFICATION:    \n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "    elif task_type == TaskType.REGRESSION:\n",
    "        criterion = nn.MSELoss(reduction='sum')\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    net.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            if task_type == TaskType.REGRESSION:\n",
    "                outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            if task_type == TaskType.CLASSFICATION:\n",
    "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        if verbose:\n",
    "            if task_type == TaskType.CLASSFICATION:\n",
    "                epoch_acc = correct / total\n",
    "                print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "            elif task_type == TaskType.REGRESSION:\n",
    "                print(f\"Epoch {epoch+1}: train loss {epoch_loss}\")\n",
    "\n",
    "def test(net, testloader, device = \"cpu\"):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "def test_regression(net, testloader, device=\"cpu\"):\n",
    "    \"\"\"Evaluate the regression model on the entire test set.\"\"\"\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    sum_of_squares, total_samples = 0.0, 0\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # To accomodate for single output layer\n",
    "            target = y.view(-1)\n",
    "            outputs = net(x).view(-1)\n",
    "\n",
    "            sum_of_squares += criterion(outputs, target).item()\n",
    "            total_samples += len(y)\n",
    "\n",
    "    if total_samples > 0:\n",
    "        avg_mse = sum_of_squares / total_samples\n",
    "    else:\n",
    "        avg_mse = 0.0\n",
    "    avg_loss = avg_mse\n",
    "\n",
    "    # Note that to make sure the consistence,\n",
    "    # we return MSE and RMSE to match {loss, accuracy as the test function}\n",
    "    return avg_loss, (avg_mse ** 0.5)\n",
    "\n",
    "# Custom Client for House Pricing Dataset\n",
    "\n",
    "class HousePricingClient(NumPyClient):\n",
    "    def __init__(\n",
    "        self,\n",
    "        net: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        test_loader: DataLoader,\n",
    "        device: torch.device,\n",
    "        client_id: int,\n",
    "        epochs: int = 1.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.client_id = client_id\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def get_parameters(self, config: Dict[str, Scalar]) -> List[np.ndarray]:\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    '''def set_parameters(self, parameters):\n",
    "        state_dict = dict(zip(self.model.state_dict().keys(), parameters))\n",
    "        self.model.load_state_dict({k: torch.tensor(v) for k, v in state_dict.items()})'''\n",
    "\n",
    "    def fit(\n",
    "        self, parameters: List[np.ndarray], config: Dict[str, Scalar]\n",
    "    ) -> Tuple[List[np.ndarray], int, Dict[str, Scalar]]:\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.train_loader, device=self.device, epochs=self.epochs, verbose=False)\n",
    "        new_params = get_parameters(self.net)\n",
    "        # Return partition-id in the metrics\n",
    "        # The simplest way to store the model\n",
    "        return new_params, len(self.train_loader.dataset), {\"partition-id\": self.client_id}\n",
    "        \n",
    "\n",
    "    def evaluate(\n",
    "        self, parameters: List[np.ndarray], config: Dict[str, Scalar]\n",
    "    ) -> Tuple[float, int, Dict[str, Scalar]]:\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, rmse = test_regression(self.net, self.val_loader, self.device)\n",
    "        print(f\"[Client {self.client_id}] Evaluate -> Loss: {loss:.4f}, RMSE: {rmse:.4f}\")\n",
    "        return float(loss), len(self.val_loader.dataset), {\"RMSE\": float(rmse)}\n",
    "\n",
    "\n",
    "class DefaultStrategy(FedAvg):\n",
    "\n",
    "    # A custom strategy to store all the parameters.\n",
    "    # https://github.com/adap/flower/issues/487\n",
    "    # https://flower.ai/docs/framework/how-to-save-and-load-model-checkpoints.html\n",
    "\n",
    "    def __init__(self, model: type, total_round: int, only_last: bool = True, save_dir: str = \"models\", *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        self.model = model\n",
    "        self.total_round = total_round\n",
    "        self.only_last = only_last\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[ClientProxy, FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "        \"\"\"\n",
    "        Aggregate model weights using weighted average.\n",
    "        Also save each client's model and the global server model.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.only_last and server_round < self.total_round:\n",
    "            return super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        # For each client which returned FitRes, save the client model\n",
    "        for (_, fit_res) in results:\n",
    "            id_ = fit_res.metrics[\"partition-id\"]\n",
    "\n",
    "            client_parameters: Optional[Parameters] = fit_res.parameters\n",
    "            if client_parameters is not None:\n",
    "                net = self.model()\n",
    "                print(f\"[Round {server_round}] Saving model for client {id_}...\")\n",
    "\n",
    "                # Convert `Parameters` to `list[np.ndarray]`\n",
    "                client_ndarrays : list[np.ndarray] = parameters_to_ndarrays(\n",
    "                    client_parameters\n",
    "                )\n",
    "\n",
    "                # Convert `list[np.ndarray]` to PyTorch `state_dict`\n",
    "                params_dict = zip(net.state_dict().keys(), client_ndarrays)\n",
    "                state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "                net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "                # Save the model to disk\n",
    "                torch.save(net.state_dict(), f\"{self.save_dir}/client-{server_round}-{id_}.pth\")\n",
    "\n",
    "        # If `aggregated_parameters` is not None, update the global net and save it\n",
    "        if aggregated_parameters is not None:\n",
    "            net = self.model()\n",
    "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "\n",
    "            # Convert `Parameters` to `list[np.ndarray]`\n",
    "            aggregated_ndarrays: list[np.ndarray] = parameters_to_ndarrays(\n",
    "                aggregated_parameters\n",
    "            )\n",
    "\n",
    "            # Convert `list[np.ndarray]` to PyTorch `state_dict`\n",
    "            params_dict = zip(net.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "            # Save the model to disk\n",
    "            torch.save(net.state_dict(), f\"{self.save_dir}/server-{server_round}.pth\")\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Federated Learning Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following class to run the experiment\n",
    "\n",
    "# You need to provide the following information:\n",
    "# 1. The Network class (dont instantiate it)\n",
    "#       (assume we use the same network for all clients and server)\n",
    "# 2. The list of data loaders for each client,\n",
    "#       where loaders is a list of loader tuples (train, val, test)\n",
    "#       i.e. loaders = [ (train_loader_0, val_loader_0, test_loader_0), ... ]\n",
    "#       NOTE: In fit and evaluate, we ONLY use the train_loader and val_loader,\n",
    "#             But we ask you to pyt them together for simplicity for any future test use.\n",
    "#       NOTE: we assume the number of clients == number of data loaders\n",
    "# 3. Number of clients\n",
    "\n",
    "# See next block for an example of how to use this class\n",
    "\n",
    "class FLExperiment:\n",
    "    \"\"\"\n",
    "    A federated learning experiment interface class.\n",
    "\n",
    "    NOTE: For each client, we now expect a tuple of three DataLoaders:\n",
    "    (train_loader, val_loader, test_loader).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_cls: type,\n",
    "        client_loaders: List[Tuple[DataLoader, DataLoader, DataLoader]],\n",
    "        num_clients: int,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        local_epochs: int = 1,\n",
    "        num_rounds: int = 5,\n",
    "        task_type: TaskType = TaskType.REGRESSION,\n",
    "        # strategy: Optional[Strategy] = None, # Is not supported yet. and may not be needed\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_cls (type): A PyTorch nn.Module class (not an instance).\n",
    "                We'll instantiate `model_cls()` for each client and server.\n",
    "            client_loaders (List[(DataLoader, DataLoader, DataLoader)]):\n",
    "                A list of (train_loader, val_loader, test_loader) for each client.\n",
    "            num_clients (int): Number of clients to simulate.\n",
    "            device (torch.device): CPU or GPU device.\n",
    "            local_epochs (int): Local epochs on each client per round.\n",
    "            num_rounds (int): How many global training rounds.\n",
    "            strategy (Optional[Strategy]): Use a custom Flower strategy or fallback to default FedAvg.\n",
    "        \"\"\"\n",
    "        if len(client_loaders) != num_clients:\n",
    "            raise ValueError(\n",
    "                f\"Number of client loader tuples ({len(client_loaders)}) does not match \"\n",
    "                f\"the number of clients ({num_clients}).\"\n",
    "            )\n",
    "\n",
    "        self.model_cls = model_cls\n",
    "        self.client_loaders = client_loaders\n",
    "        self.num_clients = num_clients\n",
    "        self.local_epochs = local_epochs\n",
    "        self.num_rounds = num_rounds\n",
    "        self.device = device\n",
    "        self.task_type = task_type\n",
    "\n",
    "        # Store final trained models\n",
    "        self._client_models: List[Optional[nn.Module]] = [None] * self.num_clients\n",
    "        self._server_model: Optional[nn.Module] = None\n",
    "\n",
    "        # Create one model per client (instantiate model_cls)\n",
    "        self.client_nets = [self.model_cls().to(self.device) for _ in range(self.num_clients)]\n",
    "\n",
    "        self.strategy = self._create_default_strategy(save_only_last=True)\n",
    "\n",
    "    def _create_default_strategy(self, save_only_last: bool) -> Strategy:\n",
    "        \"\"\"Create a default FedAvg strategy with a minimal server_evaluate.\"\"\"\n",
    "\n",
    "        def server_evaluate(\n",
    "            server_round: int,\n",
    "            parameters: NDArrays,\n",
    "            config: Dict[str, Scalar]\n",
    "        ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "            # Minimal server eval (no real evaluation)\n",
    "            net = self.model_cls().to(self.device)\n",
    "            set_parameters(net, parameters)\n",
    "            print(f\"[Server] Round {server_round} - no global evaluation implemented.\")\n",
    "            return None\n",
    "        \n",
    "        def weighted_average(metrics: List[Tuple[int, Dict[str, Scalar]]]) -> Dict[str, Scalar]:\n",
    "            accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "            examples = [num_examples for num_examples, _ in metrics]\n",
    "            if sum(examples) == 0:\n",
    "                return {\"accuracy\": 0.0}\n",
    "            return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "        def weighted_average_regression(metrics: List[Tuple[int, Dict[str, Scalar]]]) -> Dict[str, Scalar]:\n",
    "            total_sum_of_squares = 0.0\n",
    "            total_samples = 0\n",
    "            for (num_examples, m) in metrics:\n",
    "                if \"RMSE\" in m:\n",
    "                    total_sum_of_squares += m[\"RMSE\"]\n",
    "                    total_samples += num_examples\n",
    "            if total_samples == 0:\n",
    "                return {\"rmse\": 0.0}\n",
    "            rmse = (total_sum_of_squares / total_samples)\n",
    "            return {\"rmse\": rmse}\n",
    "        \n",
    "        if self.task_type == TaskType.CLASSFICATION:\n",
    "            aggregation_fn = weighted_average\n",
    "        else:\n",
    "            aggregation_fn = weighted_average_regression\n",
    "\n",
    "        default_strategy = DefaultStrategy(\n",
    "            model = self.model_cls,\n",
    "            total_round = self.num_rounds,\n",
    "            only_last = True,\n",
    "            fraction_fit=1.0,\n",
    "            fraction_evaluate=1.0,\n",
    "            min_fit_clients=self.num_clients,\n",
    "            min_evaluate_clients=self.num_clients,\n",
    "            min_available_clients=self.num_clients,\n",
    "            evaluate_fn=server_evaluate,\n",
    "            evaluate_metrics_aggregation_fn=aggregation_fn,\n",
    "        )\n",
    "        return default_strategy\n",
    "\n",
    "    def _client_fn(self, context: Context) -> Client:\n",
    "        \"\"\"Construct one Flower client using the partition_id to pick (train, val, test).\"\"\"\n",
    "        partition_id = context.node_config[\"partition-id\"]\n",
    "        trainloader, valloader, testloader = self.client_loaders[partition_id]\n",
    "        net = self.client_nets[partition_id]\n",
    "\n",
    "        client = HousePricingClient(\n",
    "            net=net,\n",
    "            train_loader=trainloader,\n",
    "            val_loader=valloader,\n",
    "            test_loader = testloader,\n",
    "            device=self.device,\n",
    "            client_id=partition_id,\n",
    "            epochs=self.local_epochs\n",
    "        )\n",
    "        return client.to_client()\n",
    "\n",
    "    def _server_fn(self, context: Context) -> ServerAppComponents:\n",
    "        \"\"\"Server-side: configure strategy and server config.\"\"\"\n",
    "        config = ServerConfig(num_rounds=self.num_rounds)\n",
    "        return ServerAppComponents(strategy=self.strategy, config=config)\n",
    "\n",
    "    def run(self, save_only_last: bool = True) -> None:\n",
    "        \"\"\"Run the federated learning simulation and store final client/server models.\n",
    "        \n",
    "        Args:\n",
    "            save_only_last (bool): Save only the last round of models.\n",
    "                Default True. If False, all models will be saved.\n",
    "        \"\"\"\n",
    "        print(\"[FLExperiment] Starting federated training...\")\n",
    "        self.strategy = self._create_default_strategy(save_only_last=save_only_last)\n",
    "        client_app = ClientApp(client_fn=self._client_fn)\n",
    "        server_app = ServerApp(server_fn=self._server_fn)\n",
    "\n",
    "        # Resource allocation\n",
    "        if self.device.type == \"cuda\":\n",
    "            backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "        else:\n",
    "            backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "        # Run the simulation\n",
    "        run_simulation(\n",
    "            client_app=client_app,\n",
    "            server_app=server_app,\n",
    "            num_supernodes=self.num_clients,\n",
    "            backend_config=backend_config,\n",
    "        )\n",
    "        print(\"[FLExperiment] Federated training finished.\")\n",
    "\n",
    "    def get_clients(self, round_num: int = 0) -> List[nn.Module]:\n",
    "        \"\"\"Return final trained models for all clients (if they have been saved).\n",
    "        \n",
    "        Args:\n",
    "            round_num (int): Round number to fetch models from. Default 0 (last round).\n",
    "        \n",
    "        Returns:\n",
    "            List[nn.Module]: List of final trained models for all clients.\n",
    "                The index of the list corresponds to the client ID \n",
    "                and the index of dataloader. \n",
    "        \"\"\"\n",
    "        assert round_num <= self.num_rounds, f\"Round {round_num} not available, only {self.num_rounds} rounds.\"\n",
    "        if round_num <= 0:\n",
    "            round_num = self.num_rounds\n",
    "        try:\n",
    "            return [\n",
    "                torch.load(f\"models/client-{round_num}-{cid}.pth\", map_location=self.device, weights_only=True)\n",
    "                for cid in range(self.num_clients)\n",
    "            ]\n",
    "        except FileNotFoundError:\n",
    "            raise RuntimeError(\"Client models are not available. Have you called run() or set only_last=True?\")\n",
    "    \n",
    "    def get_client_dataloader_tuples(self, round_num: int = 0) -> List[Tuple[nn.Module, Tuple[DataLoader, DataLoader, DataLoader]]]:\n",
    "        \"\"\"Return the dataloaders for all clients.\n",
    "         \n",
    "        Args:\n",
    "            round_num (int): Round number to fetch models from. Default 0 (last round).\n",
    "        \n",
    "        Returns:\n",
    "            List[Tuple[nn.Module, Tuple[DataLoader, DataLoader, DataLoader]]]:\n",
    "                List of (client_model, (train_loader, val_loader, test_loader))\n",
    "        \"\"\"\n",
    "        assert round_num <= self.num_rounds, f\"Round {round_num} not available, only {self.num_rounds} rounds.\"\n",
    "        if round_num <= 0:\n",
    "            round_num = self.num_rounds\n",
    "        try:\n",
    "            clients = self.get_clients(round_num)\n",
    "            return list(zip(clients, self.client_loaders)) \n",
    "        except FileNotFoundError:\n",
    "            raise RuntimeError(\"Client dataloaders are not available. Have you called run() or set only_last=True?\")\n",
    "\n",
    "    def get_server(self, round_num: int = 0) -> nn.Module:\n",
    "        \"\"\"Return the final server model (if stored).\n",
    "\n",
    "        Args:\n",
    "            round_num (int): Round number to fetch models from. Default 0 (last round).\n",
    "        \n",
    "        Returns:\n",
    "            nn.Module: The final server model.\n",
    "        \"\"\"\n",
    "        assert round_num <= self.num_rounds, f\"Round {round_num} not available, only {self.num_rounds} rounds.\"\n",
    "        if round_num <= 0:\n",
    "            round_num = self.num_rounds\n",
    "        try:\n",
    "            return torch.load(f\"models/server-{round_num}.pth\", map_location=self.device, weights_only=True)\n",
    "        except FileNotFoundError:\n",
    "            raise RuntimeError(\"Server model is not available. Have you called run() or set only_last=True?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Different Types of Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple neural networks to use as models\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size = NUM_FEATURES):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class EZNet(nn.Module):\n",
    "    def __init__(self, in_features=NUM_FEATURES):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size=NUM_FEATURES):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generate / Load Data & Create Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path = \"\"\n",
    "loaders = [\n",
    "    load_data(client_id, path) for client_id in range(1, NUM_CLIENTS + 1)\n",
    "]\n",
    "'''\n",
    "\n",
    "# Generate datasets. If you want to re-use a dataset, use load_data instead\n",
    "client_datasets = generate_house_pricing_dataset(\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    num_features=NUM_FEATURES,\n",
    "    min_samples=MIN_SAMPLES,\n",
    "    max_samples=MAX_SAMPLES,\n",
    "    num_rouge_clients=NUM_ROUGE_CLIENTS,\n",
    "    distributions=DISTRIBUTIONS,\n",
    "    is_sum=True,\n",
    "    path=\"./Test_20250111\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create train, val, test loaders\n",
    "loaders = create_client_loaders(\n",
    "    client_datasets, train_ratio=0.7, val_ratio=0.2, batch_size=16, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create and Run The Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FLExperiment] Starting federated training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 0 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 1 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 3] Evaluate -> Loss: 6204028.1972, RMSE: 2490.7887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 2 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 4] Evaluate -> Loss: 6918559.6741, RMSE: 2630.3155\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 3 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 0] Evaluate -> Loss: 6701863.7990, RMSE: 2588.7958\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 4 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 4] Evaluate -> Loss: 6918559.7630, RMSE: 2630.3155\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 5 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 4] Evaluate -> Loss: 6918559.6741, RMSE: 2630.3155\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 6 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=30760)\u001b[0m [Client 2] Evaluate -> Loss: 5841260.3000, RMSE: 2416.8699\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 7 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 4] Evaluate -> Loss: 6918559.6741, RMSE: 2630.3155\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 8 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 3] Evaluate -> Loss: 6204028.1972, RMSE: 2490.7887\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 9 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 1] Evaluate -> Loss: 6637752.4143, RMSE: 2576.3836\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 10] Saving model for client 4...\n",
      "[Round 10] Saving model for client 3...\n",
      "[Round 10] Saving model for client 1...\n",
      "[Round 10] Saving model for client 0...\n",
      "[Round 10] Saving model for client 2...\n",
      "Saving round 10 aggregated_parameters...\n",
      "[Server] Round 10 - no global evaluation implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 118.35s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 6488664.743893929\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 6488664.799720866\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 6488664.76064201\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'rmse': [(1, 8.864726807466392),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (2, 8.864726817340816),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (3, 8.864726817340815),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (4, 8.86472684615293),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (5, 8.864726817340816),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (6, 8.864726817340816),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (7, 8.864726817340815),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (8, 8.864726817340816),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (9, 8.864726817340816),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (10, 8.864726817340816)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=51112)\u001b[0m [Client 2] Evaluate -> Loss: 5841260.3000, RMSE: 2416.8699\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=39456)\u001b[0m [Client 0] Evaluate -> Loss: 6701863.7990, RMSE: 2588.7958\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "[FLExperiment] Federated training finished.\n"
     ]
    }
   ],
   "source": [
    "fl_exp = FLExperiment(\n",
    "    model_cls=EZNet,\n",
    "    client_loaders=loaders,\n",
    "    num_clients=5,\n",
    "    num_rounds=10,\n",
    "    local_epochs=50,\n",
    "    task_type = TaskType.REGRESSION\n",
    ")\n",
    "\n",
    "\n",
    "fl_exp.run(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Output the Statistics for each Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client_0 loss: 6653907.938461538, RMSE: 2579.516997125923\n",
      "Client_1 loss: 6628783.492063492, RMSE: 2574.6424008128765\n",
      "Client_2 loss: 5880526.819672131, RMSE: 2424.979756548935\n",
      "Client_3 loss: 6147990.48951049, RMSE: 2479.51416400683\n",
      "Client_4 loss: 6909169.352941177, RMSE: 2628.5298843538335\n"
     ]
    }
   ],
   "source": [
    "clients = fl_exp.get_clients()\n",
    "for i, client in enumerate(clients):\n",
    "    model = EZNet().to(DEVICE)\n",
    "    model.load_state_dict(client)\n",
    "    model.eval()\n",
    "\n",
    "    _, _, test_loader = loaders[i]\n",
    "    loss, rmse = test_regression(model, test_loader)\n",
    "    print(f'Client_{i} loss: {loss}, RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Test Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barbi\\Documents\\ETH\\HS 2024\\Deep Learning\\eth-dl-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\barbi\\Documents\\ETH\\HS 2024\\Deep Learning\\eth-dl-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([12, 1])) that is different to the input size (torch.Size([12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 123.72262602168801\n",
      "Epoch 2: train loss 121.67161010452921\n",
      "Epoch 3: train loss 121.84293470337492\n",
      "Epoch 4: train loss 120.80265381437907\n",
      "Epoch 5: train loss 120.35047023104265\n",
      "Epoch 6: train loss 119.62367313620038\n",
      "Epoch 7: train loss 120.13106822515552\n",
      "Epoch 8: train loss 119.67532413717694\n",
      "Epoch 9: train loss 118.71319442676707\n",
      "Epoch 10: train loss 119.29284074973157\n",
      "Epoch 11: train loss 119.12419612938758\n",
      "Epoch 12: train loss 119.29444718925873\n",
      "Epoch 13: train loss 119.38451577136867\n",
      "Epoch 14: train loss 119.50294125814574\n",
      "Epoch 15: train loss 119.35580285239558\n",
      "Epoch 16: train loss 119.51745840497492\n",
      "Epoch 17: train loss 119.32753041344232\n",
      "Epoch 18: train loss 119.46318068662526\n",
      "Epoch 19: train loss 119.24895842493427\n",
      "Epoch 20: train loss 119.15882866303502\n",
      "Epoch 21: train loss 119.53557004521808\n",
      "Epoch 22: train loss 119.21115307559334\n",
      "Epoch 23: train loss 119.02346404016865\n",
      "Epoch 24: train loss 119.19642487295431\n",
      "Epoch 25: train loss 118.7215384533055\n",
      "Epoch 26: train loss 119.07118499900493\n",
      "Epoch 27: train loss 118.9516016521725\n",
      "Epoch 28: train loss 119.32231624657508\n",
      "Epoch 29: train loss 118.90223607067813\n",
      "Epoch 30: train loss 119.07677824915302\n",
      "Epoch 31: train loss 119.16637062687444\n",
      "Epoch 32: train loss 119.1051025390625\n",
      "Epoch 33: train loss 119.24642087384987\n",
      "Epoch 34: train loss 119.2174536537785\n",
      "Epoch 35: train loss 119.15034716276196\n",
      "Epoch 36: train loss 119.35031156856301\n",
      "Epoch 37: train loss 119.12037875641013\n",
      "Epoch 38: train loss 119.3756652398132\n",
      "Epoch 39: train loss 119.44368338923884\n",
      "Epoch 40: train loss 119.03789921620445\n",
      "Epoch 41: train loss 119.01514047920986\n",
      "Epoch 42: train loss 118.68625253975674\n",
      "Epoch 43: train loss 119.34477884735541\n",
      "Epoch 44: train loss 118.99545288085938\n",
      "Epoch 45: train loss 119.700256853872\n",
      "Epoch 46: train loss 119.14448330413674\n",
      "Epoch 47: train loss 119.40826604038618\n",
      "Epoch 48: train loss 119.39853896009978\n",
      "Epoch 49: train loss 119.29549426038119\n",
      "Epoch 50: train loss 118.68467350819664\n",
      "Epoch 51: train loss 119.19376666172985\n",
      "Epoch 52: train loss 119.08526755961196\n",
      "Epoch 53: train loss 119.09074438013737\n",
      "Epoch 54: train loss 119.2619639030565\n",
      "Epoch 55: train loss 119.19389654222823\n",
      "Epoch 56: train loss 118.93453451581476\n",
      "Epoch 57: train loss 119.06412213221546\n",
      "Epoch 58: train loss 119.47008937456032\n",
      "Epoch 59: train loss 119.45588814251796\n",
      "Epoch 60: train loss 118.94919792283768\n",
      "Epoch 61: train loss 118.98488945983597\n",
      "Epoch 62: train loss 119.02671184810981\n",
      "Epoch 63: train loss 118.86849614003258\n",
      "Epoch 64: train loss 119.36071874971073\n",
      "Epoch 65: train loss 119.3810506522373\n",
      "Epoch 66: train loss 119.2964742940749\n",
      "Epoch 67: train loss 119.17343609705921\n",
      "Epoch 68: train loss 118.85987463494612\n",
      "Epoch 69: train loss 119.65357117856283\n",
      "Epoch 70: train loss 119.11438125682668\n",
      "Epoch 71: train loss 118.70400299506164\n",
      "Epoch 72: train loss 118.91244340507905\n",
      "Epoch 73: train loss 119.28272294320202\n",
      "Epoch 74: train loss 119.2319172502129\n",
      "Epoch 75: train loss 119.35117253308047\n",
      "Epoch 76: train loss 119.21746370577699\n",
      "Epoch 77: train loss 119.26950955503925\n",
      "Epoch 78: train loss 119.45376507365873\n",
      "Epoch 79: train loss 119.32441075040266\n",
      "Epoch 80: train loss 119.20427642388367\n",
      "Epoch 81: train loss 119.43727842213418\n",
      "Epoch 82: train loss 119.02379575611856\n",
      "Epoch 83: train loss 119.41512584234302\n",
      "Epoch 84: train loss 119.46161691385423\n",
      "Epoch 85: train loss 119.63923109877166\n",
      "Epoch 86: train loss 119.3586665872149\n",
      "Epoch 87: train loss 119.57165859999814\n",
      "Epoch 88: train loss 118.80353231565647\n",
      "Epoch 89: train loss 119.14645711166598\n",
      "Epoch 90: train loss 118.80694081094028\n",
      "Epoch 91: train loss 119.03526530333605\n",
      "Epoch 92: train loss 118.90878888894031\n",
      "Epoch 93: train loss 119.15302265763847\n",
      "Epoch 94: train loss 119.60938628137959\n",
      "Epoch 95: train loss 119.21062118747223\n",
      "Epoch 96: train loss 119.01814197702996\n",
      "Epoch 97: train loss 119.35504309487004\n",
      "Epoch 98: train loss 118.80719905328976\n",
      "Epoch 99: train loss 118.87474696444109\n",
      "Epoch 100: train loss 118.72244689362874\n",
      "(6.654374613306829, 2.579607453336036)\n"
     ]
    }
   ],
   "source": [
    "eznet = EZNet()\n",
    "train(eznet, loaders[0][0], epochs=100, verbose=True, task_type=TaskType.REGRESSION)\n",
    "print(test_regression(eznet, loaders[0][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
