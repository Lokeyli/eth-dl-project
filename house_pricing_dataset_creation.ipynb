{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clients and features\n",
    "NUM_CLIENTS = 5\n",
    "NUM_FEATURES = 8\n",
    "\n",
    "# Sample size range\n",
    "MIN_SAMPLES = 50\n",
    "MAX_SAMPLES = 200\n",
    "\n",
    "# Number of rouge clients\n",
    "NUM_ROUGE_CLIENTS = 0\n",
    "\n",
    "# Distribution configuration\n",
    "DISTRIBUTIONS = {\n",
    "    'Square Meters': {'type': 'normal', 'mu_range': (100, 300), 'sigma_range': (10, 30)},\n",
    "    'Year Built': {'type': 'normal', 'mu_range': (1950, 2020), 'sigma_range': (5, 20)},\n",
    "    'Neighborhood Quality': {'type': 'categorical', 'categories': ['Low', 'Medium', 'High'], 'prob_range': [(0.5, 0.3, 0.2), (0.3, 0.4, 0.3)]},\n",
    "    'Distance to Amenities': {'type': 'uniform', 'low_range': (100, 1000), 'high_range': (5, 20)},\n",
    "    'Number of Rooms': {'type': 'poisson', 'lambda_range': (2, 5)},\n",
    "    'Lot Size': {'type': 'normal', 'mu_range': (500, 2000), 'sigma_range': (100, 300)},\n",
    "    'House Style': {'type': 'categorical', 'categories': ['Single Family', 'Condo', 'Townhouse'], 'prob_range': [(0.6, 0.3, 0.1), (0.4, 0.4, 0.2)]},\n",
    "    'Local Economic Index': {'type': 'normal', 'mu_range': (50, 150), 'sigma_range': (10, 30)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature(feature_name, dist_params, num_samples):\n",
    "    \"\"\"Generates data for a specific feature based on its distribution.\"\"\"\n",
    "    dist_type = dist_params['type']\n",
    "    if dist_type == 'normal':\n",
    "        mu = np.random.uniform(*dist_params['mu_range'])\n",
    "        sigma = np.random.uniform(*dist_params['sigma_range'])\n",
    "        if feature_name == \"Year Built\":\n",
    "            return np.round(np.random.normal(mu, sigma, num_samples)).astype(int), {'mu': mu, 'sigma': sigma}\n",
    "        return np.random.normal(mu, sigma, num_samples), {'mu': mu, 'sigma': sigma}\n",
    "    elif dist_type == 'uniform':\n",
    "        low = np.random.uniform(*dist_params['low_range'])\n",
    "        high = np.random.uniform(*dist_params['high_range'])\n",
    "        return np.random.uniform(low, high, num_samples), {'low': low, 'high': high}\n",
    "    elif dist_type == 'categorical':\n",
    "        prob = dist_params['prob_range'][np.random.randint(0, len(dist_params['prob_range']))]\n",
    "        return np.random.choice(dist_params['categories'], num_samples, p=prob), {'probabilities': prob}\n",
    "    elif dist_type == 'poisson':\n",
    "        lam = np.random.uniform(*dist_params['lambda_range'])\n",
    "        return np.random.poisson(lam, num_samples), {'lambda': lam}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distribution type: {dist_type}\")\n",
    "    \n",
    "def encode_categorical_features(client_data):\n",
    "    \"\"\"Encodes categorical features as numerical values.\"\"\"\n",
    "    encoded_data = {}\n",
    "    encoding_maps = {}\n",
    "    for feature_name, values in client_data.items():\n",
    "        if isinstance(values[0], str):  # Check if the feature is categorical\n",
    "            unique_values = list(set(values))\n",
    "            encoding_map = {val: idx for idx, val in enumerate(unique_values)}\n",
    "            encoded_data[feature_name] = np.array([encoding_map[val] for val in values])\n",
    "            encoding_maps[feature_name] = encoding_map\n",
    "        else:\n",
    "            encoded_data[feature_name] = values\n",
    "    return encoded_data, encoding_maps\n",
    "\n",
    "def decode_categorical_features(client_data, encoding_maps):\n",
    "    \"\"\"Decodes numerical categorical features back to their string values.\"\"\"\n",
    "    decoded_data = {}\n",
    "    for feature_name, values in client_data.items():\n",
    "        if feature_name in encoding_maps:\n",
    "            decoding_map = {v: k for k, v in encoding_maps[feature_name].items()}\n",
    "            decoded_data[feature_name] = [decoding_map[val] for val in values]\n",
    "        else:\n",
    "            decoded_data[feature_name] = values\n",
    "    return decoded_data\n",
    "\n",
    "def generate_target_variable(features, weights, noise_std=1000):\n",
    "    \"\"\"Generates the target variable (house price) as a weighted sum of features with noise.\"\"\"\n",
    "    linear_combination = sum(w * features[i] for i, w in enumerate(weights))\n",
    "    noise = np.random.normal(0, noise_std, len(features[0]))\n",
    "    return linear_combination + noise\n",
    "\n",
    "def add_noise_to_features(client_data, noise_level=0.5):\n",
    "    \"\"\"Adds noise to numerical features in the client data.\"\"\"\n",
    "    noisy_data = {}\n",
    "    for feature_name, feature_values in client_data.items():\n",
    "        if feature_name != 'House Price' and np.issubdtype(type(feature_values[0]), np.number):  # Only numerical features\n",
    "            noise = np.random.normal(0, noise_level * np.std(feature_values), len(feature_values))\n",
    "            noisy_data[feature_name] = feature_values + noise\n",
    "        else:\n",
    "            noisy_data[feature_name] = feature_values\n",
    "    return noisy_data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"Saves a DataFrame to a CSV file.\"\"\"\n",
    "    data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated datasets for 5 clients, including 0 rouge clients. Check the house_pricing_datasets_0_rouge directory.\n"
     ]
    }
   ],
   "source": [
    "# Output directories\n",
    "output_dir = Path(\"house_pricing_datasets_0_rouge\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "metadata = []\n",
    "\n",
    "# Select rouge clients\n",
    "rouge_clients = set(np.random.choice(range(1, NUM_CLIENTS + 1), NUM_ROUGE_CLIENTS, replace=False))\n",
    "\n",
    "for client_id in range(1, NUM_CLIENTS + 1):\n",
    "    # Random number of samples for this client\n",
    "    num_samples = np.random.randint(MIN_SAMPLES, MAX_SAMPLES + 1)\n",
    "\n",
    "    client_data = {}\n",
    "    client_metadata = {'Client_ID': client_id, 'Is_Rouge': client_id in rouge_clients}\n",
    "\n",
    "    # Generate features\n",
    "    for feature_name, dist_params in DISTRIBUTIONS.items():\n",
    "        feature_data, params = generate_feature(feature_name, dist_params, num_samples)\n",
    "        client_data[feature_name] = feature_data\n",
    "        client_metadata[feature_name] = params\n",
    "\n",
    "    # Add noise for rouge clients\n",
    "    if client_id in rouge_clients:\n",
    "        client_data = add_noise_to_features(client_data)\n",
    "\n",
    "    # Encode categorical features\n",
    "    encoded_client_data, encoding_maps = encode_categorical_features(client_data)\n",
    "\n",
    "    # Generate target variable (house price)\n",
    "    weights = np.random.uniform(0.1, 1, NUM_FEATURES)\n",
    "    features = [encoded_client_data[feature_name] for feature_name in DISTRIBUTIONS.keys()]\n",
    "    encoded_client_data['House Price'] = generate_target_variable(features, weights)\n",
    "\n",
    "    # Decode categorical features before saving\n",
    "    decoded_client_data = decode_categorical_features(encoded_client_data, encoding_maps)\n",
    "\n",
    "    # Save client dataset to CSV\n",
    "    client_df = pd.DataFrame(decoded_client_data)\n",
    "    save_to_csv(client_df, output_dir / f\"client_{client_id}.csv\")\n",
    "\n",
    "    # Save metadata\n",
    "    client_metadata['Encoding Maps'] = encoding_maps\n",
    "    metadata.append(client_metadata)\n",
    "\n",
    "# Save metadata to a CSV file\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "save_to_csv(metadata_df, output_dir / \"metadata.csv\")\n",
    "\n",
    "# Summary\n",
    "print(f\"Generated datasets for {NUM_CLIENTS} clients, including {NUM_ROUGE_CLIENTS} rouge clients. Check the {output_dir} directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
