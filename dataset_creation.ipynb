{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "from scipy.stats import norm, bernoulli, poisson, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Parameter Configuration \n",
    "## Seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clients\n",
    "X = 10\n",
    "\n",
    "# Numer of features per client\n",
    "Y = 20\n",
    "\n",
    "# Types of distributions\n",
    "distributions = ['normal', 'standard_normal', 'bernoulli', 'poisson', 't']\n",
    "\n",
    "# Multiplier for outlier amplification\n",
    "outlier_amplification = 5\n",
    "\n",
    "# Variance for additive noise\n",
    "noise_variance = 0.1\n",
    "\n",
    "# Percentage of features to apply noise to\n",
    "percent_noisy_features = 0.2\n",
    "\n",
    "# Percentage of clients with noisy datasets\n",
    "percent_noisy_clients = 0.3\n",
    "\n",
    "# Range for number of samples\n",
    "min_samples = 50\n",
    "max_samples = 200\n",
    "\n",
    "# Path for storing \n",
    "path = \"./Datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(distribution, size):\n",
    "    \"\"\"Generate data based on the specifid distribution.\"\"\"\n",
    "    if distribution == 'normal':\n",
    "        return np.random.normal(loc=0, scale=1, size=size)\n",
    "    elif distribution == 'standard_normal':\n",
    "        return np.random.standard_normal(size=size)\n",
    "    elif distribution == 'bernoulli':\n",
    "        return bernoulli.rvs(p=0.5, size=size)\n",
    "    elif distribution == 'poisson':\n",
    "        return poisson.rvs(mu=3, size=size)\n",
    "    elif distribution == 't':\n",
    "        return t.rvs(df=10, size=size)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported distribution: {distribution}\")\n",
    "    \n",
    "def add_outliers(data, amplification):\n",
    "    \"\"\"Add outliers to a portion of the dataset.\"\"\"\n",
    "    num_outliers = max(1, len(data) // 10)  # Add outliers to 10% of the data\n",
    "    outlier_indices = np.random.choice(len(data), size=num_outliers, replace=False)\n",
    "    data[outlier_indices] *= amplification\n",
    "    return data\n",
    "\n",
    "def add_noise(data, variance, percent_features):\n",
    "    \"\"\"Add noise to a subset of features in the dataset.\"\"\"\n",
    "    data = data.astype(float) # To avoid type mismatch if bernoulli or possion\n",
    "    num_features = data.shape[1]\n",
    "    num_noisy_features = int(percent_features * num_features)\n",
    "    noisy_features = np.random.choice(num_features, size=num_noisy_features, replace=False)\n",
    "    noise = np.random.normal(loc=0, scale=variance, size=(data.shape[0], len(noisy_features)))\n",
    "    data[:, noisy_features] += noise\n",
    "    return data\n",
    "\n",
    "def save_datasets(datasets, prefix, path=path):\n",
    "    \"\"\"Save datasets to CSV files at the specified path.\"\"\"\n",
    "    for i, data in enumerate(datasets):\n",
    "        columns = [f\"Feature{str(j+1).zfill(2)}\" for j in range(Y)]\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df.to_csv(f\"{path}/{prefix}_client_{i}.csv\", index=False)\n",
    "\n",
    "def save_distributions_X1(feature_distributions_list, path=path):\n",
    "    \"\"\"Save the distribution information for X1 to a CSV file.\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"Client\": [f\"Client_{i}\" for i in range(X)],\n",
    "        \"Distribution\": [dists[0] for dists in feature_distributions_list] # Same for all features (per client)\n",
    "    })\n",
    "    df.to_csv(f\"{path}/X1_distributions.csv\", index=False)\n",
    "\n",
    "def save_distributions_X2(feature_distributions_list, path=path):\n",
    "    \"\"\"Save the distribution information for X2 to a CSV file.\"\"\"\n",
    "    records = []\n",
    "    for client_idx, distributions in enumerate(feature_distributions_list):\n",
    "        record = {\"Client\": f\"Client_{client_idx}\"}\n",
    "        for feature_idx, dist in enumerate(distributions):\n",
    "            record[f\"Feature{str(feature_idx + 1).zfill(2)}\"] = dist\n",
    "        records.append(record)\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(f\"{path}/X2_distributions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1: Each feature for a specific client comes from the same distribution\n",
    "def create_X1():\n",
    "    datasets = []\n",
    "    feature_distributions_list = [] # Track distributions for each client\n",
    "    for client in range(X):\n",
    "        # Random number of samples in the range [min_samples, max_samples]\n",
    "        Z = np.random.randint(min_samples, max_samples + 1)\n",
    "        distribution = random.choice(distributions)\n",
    "        data = np.array([generate_data(distribution, Z) for _ in range(Y)]).T\n",
    "        data = add_outliers(data, outlier_amplification)\n",
    "        datasets.append(data)\n",
    "        feature_distributions_list.append([distribution] * Y)\n",
    "    return datasets, feature_distributions_list\n",
    "\n",
    "# X2: Features for a client may come from different distributions\n",
    "def create_X2():\n",
    "    datasets = []\n",
    "    feature_distributions_list = []\n",
    "    for client in range(X):\n",
    "        Z = np.random.randint(min_samples, max_samples + 1)\n",
    "        data = []\n",
    "        feature_distributions = []\n",
    "        for feature in range(Y):\n",
    "            distribution = random.choice(distributions)\n",
    "            data.append(generate_data(distribution, Z))\n",
    "            feature_distributions.append(distribution)\n",
    "        data = np.array(data).T\n",
    "        data = add_outliers(data, outlier_amplification)\n",
    "        datasets.append(data)\n",
    "        feature_distributions_list.append(feature_distributions)\n",
    "    return datasets, feature_distributions_list\n",
    "\n",
    "# X1' and X2': Perturbed datasets\n",
    "def perturb_datasets(datasets):\n",
    "    perturbed = []\n",
    "    num_noisy_clients = int(percent_noisy_clients * X)\n",
    "    noisy_clients = random.sample(range(X), k=num_noisy_clients)\n",
    "    for idx, data in enumerate(datasets):\n",
    "        if idx in noisy_clients:\n",
    "            data = add_noise(data, noise_variance, percent_noisy_features)\n",
    "        perturbed.append(data)\n",
    "    return perturbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Generate and Save Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X1 and X2\n",
    "X1, X1_distributions = create_X1()\n",
    "X2, X2_distributions = create_X2()\n",
    "\n",
    "# Create X1' and X2'\n",
    "X1_prime = perturb_datasets(X1)\n",
    "X2_prime = perturb_datasets(X2)\n",
    "\n",
    "# Save datasets\n",
    "save_datasets(X1, \"X1\")\n",
    "save_datasets(X1_prime, \"X1_prime\")\n",
    "save_datasets(X2, \"X2\")\n",
    "save_datasets(X2_prime, \"X2_prime\")\n",
    "\n",
    "# Save distribution information\n",
    "save_distributions_X1(X1_distributions)\n",
    "save_distributions_X2(X2_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
